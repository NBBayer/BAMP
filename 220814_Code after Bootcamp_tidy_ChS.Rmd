---
title: "R Notebook"
output:
  html_document:
    df_print: paged

---

# 0 - General

```{r setup}
library(knitr)
knitr::opts_knit$set(root.dir = normalizePath("C:/Users/chris/Betterspace GmbH/Team Mannheim Business School - Dokumente/General/04_Data & Analysis/01_Data/Hotel am Kurpark_2981"))
```


Installing packages to convert Notebook to html/pdf/...

```{r}
#install.packages("htmltools")
library(htmltools)

```

Required libraries

```{r}

#install.packages("lubridate")
#install.packages("Microsoft365R")
#install.packages("rdwd")
#install.packages("here")
#install.packages("stringr")

library(tidyr)
library(dplyr)
library(fasttime)
library(lubridate)
library(ggplot2)
library(Microsoft365R)
library(AzureAuth)
library(AzureGraph)
library("stringr")
library(rdwd)
library(tidyverse)
library(here)
library(dbplyr)


```


```{r}

#Retrieving all the CSV data from Sharepoint:
# Set the site and retrieve the link names
site <- get_sharepoint_site(site_url = "https://mssdconcept.sharepoint.com/sites/TeamMannheimBusinessSchool")
url <- "General/04_Data & Analysis/01_Data/Test Hotel/"
drv <- site$get_drive()
links <- drv$list_items(url)
links <- links$name

# Create the correct path by adding the link names to the original path
list = c()
for (i in links){
  d =paste(url,i, sep ="")
  list = c(list,d)}
list <- list[grepl("csv", list)]
list


# Bulk download all the files from the Folder 
for (i in 1:length(list)){
  drv$download_file(list[i])
}

### NB: Discussion if the Import might be also be done automaticaly??

#Merge the Heating Data from the Sharepoint File
#I will continue working on this part 

```

Christians Area

# 1 - Data preparation

-- LIST OF FUNCTIONS --

1) merge_heating(): Merges single files per room with heating data into one data
frame and formats data

2) create_widemax_TFX(): Brings long heating data into maximum wide format (one
line per timestamp) and adds TFX-data. Caution with column names, might cause errors
if they differ -> not yet generalizable

3) create_widemax_TFX_agg(): same as function 2, but for aggregated data (aggrgation 
over roomTypes)

4) aggregate_room(): Aggregate long format data set over rooms 

5) 


-- END: LIST OF FUNCTIONS --

## 1.1 - Merging and changing format to wide

Merge Code
This code merges all heating-data files (one per room) into one central file 
with all the heating data. In addition, columns and columns names are adjusted
so the data frame is easy to analyze

1) import all files from working directory -> IMPORTANT TO SET WORKING DIRECTORY at the top

```{r}

#Input for function: working directory in "wd"
merge_heating <- function(wd){
  setwd(wd)
  #Create data frame with list of all files in working directory
  data_frame_names <- list.files(pattern = "*.csv")       # Get all file names
  #data_frame_names 
  data_frame_list <- lapply(data_frame_names, read.csv2)  # Read all data frames
  #data_frame_list #uncomment to see all files (takes a long time!)
  
  #length(data_frame_list)
  
  #data_frame_list[1]
  
  #Empty new data frame to store merged files/dfcs
  dfcs <- data.frame()
  
  #for loop transforms each file so there is one column with time stamp
  # (existing), one with the measured KPI and one with the measured value
  # All are saved in one data frame with this structure of three columns
  i= 1
  for (i in 1:length(data_frame_list)){
    
    var <- pivot_longer(as.data.frame(data_frame_list[i]) %>%
                          mutate(across(c(!"Zeit"), as.character)), cols = c(!"Zeit"), 
                        names_to = "Descr", values_to = "Value")
    
    dfcs <- rbind(dfcs, var)
    
  }
  
  #Exchange all occurences of .occ with .all.occ to prevent mismatch of columns 
  #when separating
  dfcs$Descr <- str_replace_all(dfcs$Descr, ".Occ", ".all.Occ")
  dfcs$Descr <- str_replace_all(dfcs$Descr, ".Text", ".all.Text")
  dfcs$Descr <- str_replace_all(dfcs$Descr, ".ClIn", ".all.ClIn")
  
  # separate ex-columntitles so different information is available in 
  # several columns (i.e. room, roomType, ...)
  dfcs <- dfcs %>% 
    separate(Descr, c("HotelID", "Room", "RoomType", "KPI"))
  
  #Split Occ from rest, since this is independent of room Type -> currently not used
  #dfcs_occ <- dfcs[dfcs$KPI == "Occ",]
  #dfcs_heat <- dfcs[dfcs$KPI != "Occ",]
  
  #Long to wide Format for each df -> currently not used
  #dfcs_heat_wide2 <- spread(dfcs_heat, key = "KPI", value = "Value")
  #dfcs_occ_wide2 <- spread(dfcs_occ, key = "KPI", value = "Value")
  
  #Bring everything into wide format, so each KPI is one column
  dfcs_wide2 <- spread(dfcs, key = "KPI", value = "Value")
  
  #saving as csv --> CHANGE PATH anf FILE NAME!!!
  write.table(dfcs_wide2, "C:/Users/chris/Downloads/HotelzumStern_2.HJ2019_heating.txt")
}

```


Data preparation
Created: 17/05/2022

This code section prepares the data for a. data exploration and b. modelling
In essence, the heating data frame is changed into a wide format (one column 
per KPI) and later into a max. wide format (one line per point in time). 
Also, TFX-data on heating/thermal energy consumption is added (dependent 
variable in models later)

dfcs: heating data in format, as specified at end of merge code

```{r}


#Required inputs: heating data in long format


create_widemax_TFX <- function(heating_long, TFX_input){
  
  dfcs <- heating_long
  #summary(dfcs)
  
  dfcs$Room <- as.factor(dfcs$Room)
  dfcs$RoomType <- as.factor(dfcs$RoomType)
  dfcs$Occ <- as.factor(dfcs$Occ)
  dfcs$Win <- as.factor(dfcs$Win)
  
  #Creating subsets for each level of information (available on different 
  # hierarchy levels)
  
  dfcs_building <- dfcs[dfcs$Room == "Build",]
  dfcs_room <- dfcs[dfcs$RoomType == "all",]
  dfcs_roomtype <- dfcs[dfcs$RoomType != "all",]
  dfcs_roomtype <- dfcs_roomtype[dfcs_roomtype$RoomType != "Build",]
  
  #Prepare each subset individually -> long to wide
  dfcs_building <- subset(dfcs_building, select = -c(Occ, T, Td, Val, Win, Room, RoomType))
  names(dfcs_building) <- c("Zeit", "HotelID", "ClIn.all.Build", "Text.all.Build")
  
  
  dfcs_room <- subset(dfcs_room, select = -c(T, Td, Val, Win, Text, ClIn))
  dfcs_room$keylw <- paste("Occ", dfcs_room$Room, dfcs_room$RoomType, sep = ".")
  dfcs_room <- subset(dfcs_room, select = -c(Room, RoomType))
  dfcs_room_wide <- spread(dfcs_room, key = "keylw", value = "Occ")
  
  
  dfcs_roomtype <- subset(dfcs_roomtype, select = -c(Occ, Text, ClIn))
  dfcs_roomtype$keylw <- paste(dfcs_roomtype$Room, dfcs_roomtype$RoomType, sep = ".")
  dfcs_roomtype <- subset(dfcs_roomtype, select = -c(Room, RoomType))
  dfcs_roomtype$keylw <- as.factor(dfcs_roomtype$keylw)
  
  #dfcs_roomtype_wide <- reshape(data = dfcs_roomtype, 
  #v.names = c("T", "Td", "Val", "Win"),
  # timevar = "keylw",
  #idvar = c("Zeit", "HotelID"),
  # direction = "wide")
  
  dfcs_roomtype_wide <- pivot_wider(dfcs_roomtype, names_from = "keylw", 
                                    values_from =  c("T", "Td", "Val", "Win"),
                                    names_sep = ".")
  
  #merge wide subsets to entire data set, based on timestamp
  dfcshelp1 <- merge(dfcs_building, dfcs_room_wide, by = "Zeit")
  dfcshelp1 <- subset(dfcshelp1, select = -c(HotelID.y))
  
  heating_widemax <- merge(dfcshelp1, dfcs_roomtype_wide, by = "Zeit")
  heating_widemax <- subset(heating_widemax, select = -c(HotelID))
  #summary(heating_widemax)
  
  #Save as csv
  #write.csv(heating_widemax, "C:/Users/chris/Downloads/HotelzumStern_2.HJ2019_heating_widemax.csv")
  
  #ASSIGN CORRECT DF when running to specific use case
  TFX_all <- TFX_input
  #heating_widemax <- heating_widemax_TFX_weather_holiday
  
  #Subsetting, to only include Leistung from TFX file
  TFX_all <- subset(TFX_all, select = c(X, Kessel.1.2.Leistung, BHKW.1.4.Leistung))
  names(TFX_all) <- c("Zeit", "Kessel_Leistung", "BHKW_Leistung")
  # tz = CEST for correct time zone!
  TFX_all$Zeit <- fastPOSIXct(TFX_all$Zeit, required.components = 5L, tz = "CEST")
  #summary(TFX_all)
  
  heating_widemax$Zeit <- fastPOSIXct(heating_widemax$Zeit, required.components = 5L, tz = "CEST")
  
  #Left join keeps all rows from heating --> many NAs since dates don't overlap entirely
  heating_widemax_TFX <- heating_widemax %>% left_join(TFX_all, by = "Zeit")
  
  #heating_widemax_TFX <- heating_widemax_TFX %>% drop_na(Kessel_Leistung)
  #summary(heating_widemax_TFX$LeistungGesamt)
  
  #Optinal: create new column with Sum of Leistung. ATTENTION: if one column contains an NA, sum is NA!!
  #heating_widemax_TFX$LeistungGesamt <- heating_widemax_TFX$Kessel_Leistung + heating_widemax_TFX$BHKW_Leistung
  
  #Export to csv
  write.csv(heating_widemax_TFX, "C:/Users/chris/Downloads/HotelamKurpark_2.HJ2020_heating_widemax_TFX.csv")

}

```

Function: Create Widemax for aggregated data sets

```{r}

create_widemax_TFX_agg <- function(heating_long_agg, TFX_input){
  
  dfcs <- heating_long_agg
  #summary(dfcs)
  
  dfcs$Room <- as.factor(dfcs$Room)
  dfcs$Occ <- as.factor(dfcs$Occ)
  dfcs$Win <- as.factor(dfcs$Win)
  
  #Creating subsets for each level of information (available on differen 
  # hierarchy levels)
  
  dfcs_building <- dfcs[dfcs$Room == "Build",]
  dfcs_room <- dfcs[dfcs$Room != "Build",]
  
  #Prepare each subset individually -> long to wide
  dfcs_building <- subset(dfcs_building, select = -c(Occ, T, Td, Val, Win, Room))
  dfcs_building$X <- NULL
  names(dfcs_building) <- c("Date", "Time", "ClIn.Build", "Text.Build")
  
  
  dfcs_room <- subset(dfcs_room, select = -c(Text, ClIn, X))
  #dfcs_room <- subset(dfcs_room, select = -c(Room, RoomType))
  #dfcs_room_wide <- spread(dfcs_room, key = "keylw", value = "Occ")
  
  
  #dfcs_roomtype_wide <- reshape(data = dfcs_roomtype, 
  #v.names = c("T", "Td", "Val", "Win"),
  # timevar = "keylw",
  #idvar = c("Zeit", "HotelID"),
  # direction = "wide")
  
  dfcs_room_wide <- pivot_wider(dfcs_room, names_from = "Room", 
                                    values_from =  c("Occ", "T", "Td", "Val", "Win"),
                                    names_sep = ".")
  
  dfcs_room_wide$datetime <- paste(dfcs_room_wide$Date, dfcs_room_wide$Time)
  dfcs_room_wide$datetime <- fastPOSIXct(dfcs_room_wide$datetime, required.components = 5L, tz = "utc" )
  
  dfcs_building$datetime <- paste(dfcs_building$Date, dfcs_building$Time)
  dfcs_building$datetime <- fastPOSIXct(dfcs_building$datetime, required.components = 5L, tz = "utc" )
  
  #merge wide subsets to entire data set, based on timestamp
  heating_widemax <- merge(dfcs_building, dfcs_room_wide, by = "datetime")
  
  heating_widemax <- subset(heating_widemax, select = -c(Date.x, Time.x))
  #summary(heating_widemax)
  
  #Save as csv
  write.csv(heating_widemax, "C:/Users/chris/Downloads/agg_widemax.csv")
  
  #ASSIGN CORRECT DF when running to specific use case
  TFX_all <- TFX_input
  #heating_widemax <- heating_widemax_TFX_weather_holiday
  
  #Subsetting, to only include Leistung from TFX file
  TFX_all <- subset(TFX_all, select = c(X, Kessel.1.2.Leistung, BHKW.1.4.Leistung))
  names(TFX_all) <- c("Zeit", "Kessel_Leistung", "BHKW_Leistung")
  TFX_all$Zeit <- fastPOSIXct(TFX_all$Zeit, required.components = 5L, tz = "CEST")
  #summary(TFX_all)
  
  heating_widemax$Zeit <- fastPOSIXct(heating_widemax$datetime, required.components = 5L, tz = "CEST")
  
  #Left join keeps all rows from heating --> many NAs since dates don't overlap entirely
  heating_widemax_TFX <- heating_widemax %>% left_join(TFX_all, by = "Zeit")
  
  #heating_widemax_TFX <- heating_widemax_TFX %>% drop_na(Kessel_Leistung)
  #summary(heating_widemax_TFX$LeistungGesamt)
  
  #Optinal: create new column with Sum of Leistung. ATTENTION: if one column contains an NA, sum is NA!!
  #heating_widemax_TFX$LeistungGesamt <- heating_widemax_TFX$Kessel_Leistung + heating_widemax_TFX$BHKW_Leistung
  
  #Export to csv
  write.csv(heating_widemax_TFX, "C:/Users/chris/Downloads/agg_widemax_TFX.csv")
  

}

```

## 1.2 - Aggregation over room Types

Aggregate function over rooms: !! Check binary variables Occ and Win !!
Check ways to summarise and NAs that result!

```{r}

aggregate_room <- function(data_long){
  
  Heating_Data_Nov2020_Num <- data_long
  Heating_Data_Nov2020_Num $Occ <- as.numeric(Heating_Data_Nov2020_Num $Occ)
  Heating_Data_Nov2020_Num $Win <- as.numeric(Heating_Data_Nov2020_Num $Win)
  
  ## 0 is NA 1 is not occupied 2 is occupied
  ## 0 is NA 1 is no open window detected 2 is open window detected
  
  # Aggregate the Num Dataset.
  hd_Nov_2020_Agg <- Heating_Data_Nov2020_Num  %>% group_by(Zeit,Room) %>% summarise(ClIn = median(ClIn, na.rm = TRUE), Occ = sum(Occ, na.rm = TRUE), T = mean(T, na.rm=TRUE), Td = mean(Td, na.rm =TRUE), Text = mean(Text, na.rm =TRUE), Val = mean(Val, na.rm =TRUE), Win = sum(Win, na.rm =TRUE))
  
  # Save as CSV
  getwd()
  write.csv(write.csv(hd_Nov_2020_Agg, "C:/Users/chris/Downloads/agg.csv"))
  
  #head(hd_Nov_2020_Agg, 50)
  #return(hd_Nov_2020_Agg)
  
}


```

## 1.3 - Feature engineering and add. data (WIP!)

Function feature engineering

```{r}
#Data set needs to be in widemax format, preferably aggregated over Room Type

feature_eng <- function(dataset){
  
  df <- dataset
  
  ## 1: Day and Weekend
  
  df$Date <- fastDate(substr(df$Zeit, 0, 10))
  df$weekday <- as.factor(weekdays(df$Date))
  df[df$weekday == "Samstag" | df$weekday ==  "Sonntag", "weekend"] <- 1
  df[df$weekday == "Montag" | df$weekday ==  "Dienstag" | df$weekday ==  "Mittwoch" | 
                            df$weekday ==  "Donnerstag" | df$weekday ==  "Freitag", "weekend"] <- 0
  df$weekend <- as.integer(df$weekend)
  
  ## 2: Occupancy ratio
  
  df$OccSum <- rowSums(df[grepl("Occ", names(df))])
  df$OccRate <- df$OccSum/sum(grepl("Occ", names(df)))
  
  ## 3: Leistung Gesamt
  
  df$Leistung_all <- rowSums(df[,c("Kessel_Leistung", "BHKW_Leistung")], na.rm = TRUE)
  
  ## 4: month, week, time of day, season
  
  df$month <- as.factor(month(df$Date))
  df$week <- as.factor(week(df$Date))
  
  # TO BE ADDED: Time of day, season?
  
  return(df)

}

```


Function external data: WIP - Weather data does not work yet!!

```{r}

#input: widemax data set, preferably with feature engineering and already aggregated over Room Tpye

external_data <- function(dataset){
  
  df <- dataset
  
  #1: Weather data from DWD
  
  #Get weather data from DWD
  #ATTENTION: ZIP FILE DOWNLOADED TO WORKING DIRECTORY
  #link <- selectDWD(id = findID(name = "Hersfeld, Bad", exactmatch = FALSE), res="hourly", var="air_temperature", per="h")
  #file <- dataDWD(link, read=FALSE)
  #clim <- readDWD(file, varnames=TRUE)
  
  ## !! CHECK TIMEZONE!!
  #clim$Time.y <- fastPOSIXct(clim$MESS_DATUM, required.components = 6L)
  #df$Time.y <- fastPOSIXct(df$Time.y, required.components = 4)
  
  #Join with heating data
  #df_weather <- left_join(df, y = clim, by = "Time.y")
  

  #2: Pubblic holidays

  #Fetch Feiertage
  # Change link if different country and/or year required!
  public_holidays <- jsonlite::fromJSON("https://date.nager.at/api/v2/publicholidays/2020/DE")
  
  public_holidays$Date.y <- public_holidays$date
  #df_weather$Date <- fastDate(substr(df_weather$Zeit, 0, 10))
  public_holidays$Date <- fastDate(public_holidays$Date)
  
  #Join with heating data
  df_weather_holiday <- left_join(df, y = public_holidays, by = "Date.y")
  #Replace NAs (no Holiday at date) with "kein Feiertag"
  df_weather_holiday$localName[is.na(df_weather_holiday$localName)] <- "kein Feiertag"
  
  df_weather_holiday$type <- NULL
  df_weather_holiday$launchYear <- NULL
  df_weather_holiday$global <- NULL
  df_weather_holiday$fixed <- NULL
  df_weather_holiday$countryCode <- NULL

  
  #3: School holidays
  
  
  #4: Delta T and Outside Temp
  
  
  #5: Heating Degree Days HDD -> Code to be adjusted
  
  # clim$date <- fastDate(substr(clim$Zeit, 0, 10))
  # #summary(clim)
  # 
  # clim <- na.omit(clim)
  # 
  # clim_agg <- aggregate(clim$TT_TU.Lufttemperatur, by = list(clim$date), FUN = "mean")
  # 
  # names(clim_agg) <- c("Date", "Avg_Temp")
  # colnames(heating_widemax_TFX)[4] <- "Date"
  # 
  # clim_agg$HDD <- ifelse(clim_agg$Avg_Temp < 18, 1, 0)
  # clim_agg$HDDindex <- ifelse(clim_agg$Avg_Temp < 18, (18-clim_agg$Avg_Temp), 0)
  # 
  # heating_widemax_TFX_weather_HDD <- heating_widemax_TFX %>% left_join(clim_agg, by = "Date")
  
  
  
  return(df_weather_holiday)
# Export to csv?
  
}

```

Check adding add. data

```{r}

tst2 <- data.frame(external_data(agg_widemax_TFX))

```



## 1.4 - Export final data set to csv -> for modelling

Data frame name and filename to be changed
```{r}

write.csv(df, "C:/Users/chris/Downloads/HotelXY_final_period.csv")


```


## 1.5 - Backlog and old Code data preparation

Turn Window detection to 1 and 0

```{r}
heating_data_rooms["Win",] <- lapply(heating_data_rooms["Win",], as.integer)
subtract1 <- function(x){
  return(x-1)
}
heating_data_rooms$Win <- lapply(heating_data_rooms$Win, subtract1)
```



Add energy cost data

```{r}
#Download energy cost data from link in relevant time frame, then import to R directory
#Link: https://www.smard.de/home/downloadcenter/download-marktdaten#!?downloadAttributes=%7B%22selectedCategory%22:3,%22selectedSubCategory%22:8,%22selectedRegion%22:%22DE%22,%22from%22:1590962400000,%22to%22:1609455599999,%22selectedFileType%22:%22CSV%22%7D

energy_cost <- Gro_handelspreise_202001010000_202005312359
#Change column name without ".x"!!!
energy_cost$Zeit.x <- fastPOSIXct(energy_cost$Datetime, required.components = 5L, tz = "cest")

heating_widemax_TFX_weather_holiday_ecosts <- left_join(heating_widemax_TFX_weather_holiday, y = energy_cost, by = "Zeit.x")
```


BOOTCAMP Data Aggregation and adding of additional variables based on 
findings from saturday

1) Importing data set heating (Nov) aggregated on room level -> added to functions


```{r}

# dfcs <- Heating_Data_Nov2020_Agg
# #summary(dfcs)
# 
# dfcs$Room <- as.factor(dfcs$Room)
# dfcs$Occ <- as.factor(dfcs$Occ)
# dfcs$Win <- as.factor(dfcs$Win)
# 
# #Creating subsets for each level of information (available on differen 
# # hierarchy levels)
# 
# dfcs_building <- dfcs[dfcs$Room == "Build",]
# dfcs_room <- dfcs[dfcs$Room != "Build",]
# 
# #Prepare each subset individually -> long to wide
# dfcs_building <- subset(dfcs_building, select = -c(Occ, T, Td, Val, Win, Room))
# dfcs_building$X <- NULL
# names(dfcs_building) <- c("Date", "Time", "ClIn.Build", "Text.Build")
# 
# 
# dfcs_room <- subset(dfcs_room, select = -c(Text, ClIn, X))
# #dfcs_room <- subset(dfcs_room, select = -c(Room, RoomType))
# #dfcs_room_wide <- spread(dfcs_room, key = "keylw", value = "Occ")
# 
# 
# #dfcs_roomtype_wide <- reshape(data = dfcs_roomtype, 
# #v.names = c("T", "Td", "Val", "Win"),
# # timevar = "keylw",
# #idvar = c("Zeit", "HotelID"),
# # direction = "wide")
# 
# dfcs_room_wide <- pivot_wider(dfcs_room, names_from = "Room", 
#                                   values_from =  c("Occ", "T", "Td", "Val", "Win"),
#                                   names_sep = ".")
# 
# dfcs_room_wide$datetime <- paste(dfcs_room_wide$Date, dfcs_room_wide$Time)
# dfcs_room_wide$datetime <- fastPOSIXct(dfcs_room_wide$datetime, required.components = 5L, tz = "utc" )
# 
# dfcs_building$datetime <- paste(dfcs_building$Date, dfcs_building$Time)
# dfcs_building$datetime <- fastPOSIXct(dfcs_building$datetime, required.components = 5L, tz = "utc" )
# 
# #merge wide subsets to entire data set, based on timestamp
# heating_widemax <- merge(dfcs_building, dfcs_room_wide, by = "datetime")
# 
# heating_widemax <- subset(heating_widemax, select = -c(Date.x, Time.x))
# #summary(heating_widemax)
# 
# #Save as csv
# write.csv(heating_widemax, "C:/Users/chris/Downloads/Heating_data_Nov2020_agg_widemax.csv")


```

2) Add TFX data -> added to functions

```{r}

# TFX_all <- TFX_all_4
# 
# 
# #Subsetting, to only include Leistung from TFX file
# TFX_all <- subset(TFX_all, select = c(X, Kessel.1.2.Leistung, BHKW.1.4.Leistung))
# names(TFX_all) <- c("Zeit", "Kessel_Leistung", "BHKW_Leistung")
# TFX_all$Zeit <- fastPOSIXct(TFX_all$Zeit, required.components = 5L, tz = "utc")
# #summary(TFX_all)
# heating_widemax$Zeit <- heating_widemax$datetime
# 
# 
# #Left join keeps all rows from heating --> many NAs since dates don't overlap entirely
# heating_widemax_TFX <- heating_widemax %>% left_join(TFX_all, by = "Zeit")
# 
# #heating_widemax_TFX <- heating_widemax_TFX %>% drop_na(Kessel_Leistung)
# #summary(heating_widemax_TFX$LeistungGesamt)
# 
# #Optinal: create new column with Sum of Leistung. ATTENTION: if one column contains an NA, sum is NA!!
# #heating_widemax_TFX$LeistungGesamt <- heating_widemax_TFX$Kessel_Leistung + heating_widemax_TFX$BHKW_Leistung
# 
# #Export to csv
# write.csv(heating_widemax_TFX, "C:/Users/chris/Downloads/Heating_data_Nov2020_agg_widemax_TFX.csv")

```

3) Data from DWD

```{r}

heating_widemax_TFX <- Heating_data_Nov2020_agg_widemax_TFX
heating_widemax_TFX$Zeit <- fastPOSIXct(heating_widemax_TFX$Zeit, required.components = 5L)

#Get weather data from DWD
#ATTENTION: ZIP FILE DOWNLOADED TO WORKING DIRECTORY
link <- selectDWD(id = findID(name = "Hersfeld, Bad", exactmatch = FALSE), res="hourly", var="air_temperature", per="h")
file <- dataDWD(link, read=FALSE)
clim <- readDWD(file, varnames=TRUE)

clim$Zeithour <- fastPOSIXct(clim$MESS_DATUM, required.components = 6L, tz = "utc")

heating_widemax_TFX$Zeithour <- substr(heating_widemax_TFX$Zeit, 0, 13)
heating_widemax_TFX$Zeithour <- fastPOSIXct(heating_widemax_TFX$Zeithour, required.components = 4)


```

3.1) Calculate HDD

```{r}

clim$date <- fastDate(substr(clim$Zeit, 0, 10))
#summary(clim)

clim <- na.omit(clim)


clim_agg <- aggregate(clim$TT_TU.Lufttemperatur, by = list(clim$date), FUN = "mean")

names(clim_agg) <- c("Date", "Avg_Temp")
colnames(heating_widemax_TFX)[4] <- "Date"

clim_agg$HDD <- ifelse(clim_agg$Avg_Temp < 18, 1, 0)

clim_agg$HDDindex <- ifelse(clim_agg$Avg_Temp < 18, (18-clim_agg$Avg_Temp), 0)


heating_widemax_TFX_weather_HDD <- heating_widemax_TFX %>% left_join(clim_agg, by = "Date")



```

4) Add Public Holidays Feiertage

```{r}

#Fetch Feiertage
# Change link if different country and/or year required!
public_holidays <- jsonlite::fromJSON("https://date.nager.at/api/v2/publicholidays/2020/DE")

public_holidays$Date <- public_holidays$date
heating_widemax_TFX_weather_HDD$Date <- fastDate(substr(heating_widemax_TFX_weather_HDD$Zeit, 0, 10))
public_holidays$Date <- fastDate(public_holidays$Date)

#Join with heating data
heating_widemax_TFX_weather_HDD_holiday <- left_join(heating_widemax_TFX_weather_HDD, y = public_holidays, by = "Date")
#Replace NAs (no Holiday at date) with "kein Feiertag"
heating_widemax_TFX_weather_HDD_holiday$localName[is.na(heating_widemax_TFX_weather_HDD_holiday$localName)] <- "kein Feiertag"


heating_widemax_TFX_weather_HDD_holiday <- subset(heating_widemax_TFX_weather_HDD_holiday, select = -c(date, name, countryCode, fixed, global
                                                                                                       , launchYear, counties, type))

```

5) Leistung Gesamt

```{r}

heating_widemax_TFX_weather_HDD_holiday$LeistungGesamt <- heating_widemax_TFX_weather_HDD_holiday$Kessel_Leistung + heating_widemax_TFX_weather_HDD_holiday$BHKW_Leistung

```


6) Weekend and Weekday

```{r}

heating_widemax_TFX_weather_HDD_holiday$weekday <- as.factor(weekdays(heating_widemax_TFX_weather_HDD_holiday$Date))
heating_widemax_TFX_weather_HDD_holiday[heating_widemax_TFX_weather_HDD_holiday$weekday == "Samstag" | heating_widemax_TFX_weather_HDD_holiday$weekday ==  "Sonntag", "weekend"] <- 1
heating_widemax_TFX_weather_HDD_holiday[heating_widemax_TFX_weather_HDD_holiday$weekday == "Montag" | heating_widemax_TFX_weather_HDD_holiday$weekday ==  "Dienstag" | heating_widemax_TFX_weather_HDD_holiday$weekday ==  "Mittwoch" | 
                          heating_widemax_TFX_weather_HDD_holiday$weekday ==  "Donnerstag" | heating_widemax_TFX_weather_HDD_holiday$weekday ==  "Freitag", "weekend"] <- 0

heating_widemax_TFX_weather_HDD_holiday$weekend <- as.integer(heating_widemax_TFX_weather_HDD_holiday$weekend)


```

7) Outside Temperature

```{r}

heating_widemax_TFX_weather_HDD_holiday <- left_join(heating_widemax_TFX_weather_HDD_holiday, y = clim, by = "Zeithour")

heating_widemax_TFX_weather_HDD_holiday <- subset(heating_widemax_TFX_weather_HDD_holiday, select = -c(STATIONS_ID, MESS_DATUM, QN_9, eor))



```


8) Auslastung / Auslastungsquote

!!! Currently in Occ 0 = n/a, 1 = False and 2 = True --> OccSum and OccRate not plausible

```{r}

heating_final <- heating_widemax_TFX_weather_HDD_holiday

heating_final$OccSum <- rowSums(heating_final[grepl("Occ", names(heating_final))])
heating_final$OccRate <- heating_final$OccSum/sum(grepl("Occ", names(heating_final)))

summary(heating_final$OccRate)
```

```{r}

write.csv(heating_final, "C:/Users/chris/Downloads/Heating_data_Nov2020_agg_widemax_TFX_addData.csv", row.names = FALSE)

```

# 2 - Data exploration 

DATA EXPLORATION

Data Exploration of raw heating data 

```{r}
#Import heating data, without TFX information
heating_data <- HotelamKurpark_2.HJ2020_heating
heating_data$Zeit <- fastPOSIXct(heating_data$Zeit, required.components = 5L)
summary(heating_data)
```
Some data preparation for data exploration

```{r}
#Drop ClIn and Text (for now, maybe analyze separately)
heating_data$ClIn <- NULL
heating_data$Text <- NULL

#Subsetting to only include guest rooms, not general ones
#Assumption: general rooms to be viewd as "fixed basic energy usage" with 
#no significant impact on change in energy consumption --> focus on guest rooms
heating_data_rooms <- subset(heating_data, grepl("Zi", heating_data$Room))

#Drop Occupancy, since its only available on level room instead of roomType 
#-> DISCUSS handling NAs
heating_data_rooms$Occ <- NULL
#summary(heating_data_rooms)
heating_data_rooms$Room <- as.factor(heating_data_rooms$Room)
heating_data_rooms$RoomType <- as.factor(heating_data_rooms$RoomType)
heating_data_rooms$Zeit <- fastPOSIXct(heating_data_rooms$Zeit, required.components = 5L)
heating_data_rooms$Win <- as.factor(heating_data_rooms$Win)

#remove all N/A's (entire rows!)
#Adjust selection in na.omit when only focussing one certain columns to not delete too much!!
heating_data_rooms <- na.omit(heating_data_rooms)
summary(heating_data_rooms)
```
Plot all data points T over time
```{r}
ggplot(data = heating_data_rooms, aes(x = Zeit, y = T)) +
  geom_point()
```

Plot mean Temperature over all rooms per point in time
```{r}
ggplot(data = heating_data_rooms, aes(x = Zeit, y = T)) +
  stat_summary(aes(y = T), fun = "mean", geom = "line", colour = "red") +
  stat_summary(aes(y=Td), fun = "mean", geom = "line", colour = "blue") +
  scale_color_manual("Legend", values = c("T" = "red", "Td" = "blue"))

```

Same chart as above, but data filtered so T and Td have to be larger than 10°C
--> assumption: anything below not plausible (threshold of 10 to be discussed)

```{r}
filter(heating_data_rooms, Room == "Zi36") %>%
  #filter(T > 10 & Td > 10) %>%
    ggplot(aes(x = Zeit)) +
      stat_summary(aes(y = T, colour = "T"), fun = "mean", geom = "line") +
      stat_summary(aes(y=Td, colour = "Td"), fun = "mean", geom = "line") +
      #stat_summary(aes(y=Val, colour = "Val"), fun = "mean", geom = "line") +
      ylab("Temperature") +
      xlab("Date") +
      labs(title = "Mean T and Td of Zi 36 per point in time Hotel Kurpark") +
      scale_color_manual("Legend", values = c("T" = "red", "Td" = "blue"))
```

```{r}
#filter(heating_data_rooms, Room == "Zi18") %>%
#  cor(as.numeric(heating_data_rooms$Td), as.numeric(heating_data_rooms$Val))
```


SUmmary
```{r}
filter(heating_data_rooms, Room == "Zi18") %>%
  #filter(T > 10 & Td > 10) %>%
  summary()
```
```{r}

heating_data$Occ <- as.factor(heating_data$Occ)

table(heating_data$Room, heating_data$Occ)

summary(heating_data$Occ)
```



One filter less than above

```{r}
filter(heating_data_rooms, T > 10 & Td > 10) %>%
  ggplot(aes(x = Zeit)) +
  stat_summary(aes(y = T, colour = "T"), fun = "mean", geom = "line") +
  stat_summary(aes(y=Td, colour = "Td"), fun = "mean", geom = "line") +
  ylab("Temperature") +
  xlab("Date") +
  labs(title = "Mean T and Td over all rooms per point in time Hotel Kurpark") +
  scale_color_manual("Legend", values = c("T" = "red", "Td" = "blue"))
```

Check plot: aggregate: Mean Temperature per point in time

```{r}

#aggregate(heating_data_rooms$T, by = list(heating_data_rooms$Zeit), FUN = "mean")
#aggregate(heating_data_rooms$Td, by = list(heating_data_rooms$Zeit), FUN = "mean")

```


Create new column that calculates delta in temperature
```{r}
heating_data_rooms$TempDelta <- heating_data_rooms$T - heating_data_rooms$Td
```

Delta of T and Td + Mean Val per point in time
```{r}
filter(heating_data_rooms, T > 10 & Td > 10) %>%
  ggplot(aes(x = Zeit)) +
  stat_summary(aes(y = TempDelta, colour = "Delta T and Td"), fun = "mean", geom = "line") +
  geom_hline(yintercept=0, color = "black", size = 2) +
  stat_summary(aes(y=Val, colour = "Val"), fun = "mean", geom = "line") +
  ylab("Temperature-Delta") +
  xlab("Date") +
  labs(title = "Mean Delta of T and Td (T-Td) over all rooms per point in time Hotel Kurpark") +
  scale_color_manual("Legend", values = c("Delta T and Td" = "blue", "Val" = "green"))
```


Delta of T and Td + Mean Val per point in time, just Zi 01
IDEA: Add external temperate to explain spikes!

```{r}
filter(heating_data_rooms, Room == "Zi36") %>%
  filter(month == 11) %>%
    ggplot(aes(x = Zeit)) +
    stat_summary(aes(y = Val, colour = "Val"), fun = "mean", geom = "line") +
    stat_summary(aes(y=T, colour = "T"), fun = "mean", geom = "line") +
    stat_summary(aes(y=Td, colour = "Td"), fun = "mean", geom = "line") +
    stat_summary(aes(y=exttemp, colour = "ext. Temp"), fun = "mean", geom = "line") +
    geom_hline(yintercept=0, color = "black", size = 1) +
    ylab("Temperature-Delta") +
    xlab("Date") +
    labs(title = "Mean Delta of T and Td (T-Td) in Zi 01 per point in time Hotel Kurpark") +
    scale_color_manual("Legend", values = c("T" = "blue", "ext. Temp" = "green", "Val" = "red", "Td" = "purple"))
```

New plot
```{r}
filter(heating_data_rooms, Room == "Zi36") %>%
  filter(month == 11) %>%
    ggplot(aes(x = Zeit)) +
    stat_summary(aes(y=Td, colour = "Td"), fun = "mean", geom = "line") +
    stat_summary(aes(y=exttemp, colour = "ext. Temp"), fun = "mean", geom = "line") +
    stat_summary(aes(y=Win, colour = "Win"), fun = "mean", geom = "line") +
    geom_hline(yintercept=0, color = "black", size = 1) +
    ylab("Temperature-Delta") +
    xlab("Date") +
    labs(title = "Mean Delta of T and Td (T-Td) in Zi 01 per point in time Hotel Kurpark") +
    scale_color_manual("Legend", values = c("Td" = "blue", "ext. Temp" = "green", "Win" = "red"))
```




Adding external temperature from DWD (just for data exploration, not part of data peparation)
```{r}
heating_data_rooms$Zeithour <- substr(heating_data_rooms$Zeit, 0, 13)
heating_data_rooms$Zeithour <- fastPOSIXct(heating_data_rooms$Zeithour, required.components = 4)

#Join with heating data
heating_data_rooms <- left_join(heating_data_rooms, y = clim, by = "Zeithour")

heating_data_rooms$exttemp <- heating_data_rooms$TT_TU.Lufttemperatur

```



Delta of T and Td per point in time, just Zi 01

```{r}
filter(heating_data_rooms, Room == "Zi36") %>%
  filter(month == 11) %>%
  ggplot(aes(x = Zeit)) +
    stat_summary(aes(y = TempDelta, colour = "Delta T and Td"), fun = "mean", geom = "line") +
    geom_hline(yintercept=0, color = "black", size = 2) +
    ylab("Temperature-Delta") +
    xlab("Date") +
    labs(title = "Mean Delta of T and Td (T-Td) in Zi 01 per point in time Hotel Kurpark") +
    scale_color_manual("Legend", values = c("Delta T and Td" = "blue"))
```

Aggregation for exploration

```{r}
df2 <- heating_data_rooms %>%
  group_by(Zeit, Room) %>%
  summarise_at(c("TempDelta", "Val"), mean)

#Correlation of T and Val per Room (mean over time)
df2_cor <- df2 %>%
  group_by(Room) %>%
  summarise(r = cor(TempDelta, Val))

df2_cor
```

Moddeling with heating_widemax_TFX-dataset

```{r}
heating_widemax_TFX <- HotelamKurpark_2.HJ2020_heating_widemax_TFX

#summary(heating_widemax_TFX)
heating_widemax_TFX$Zeit <- fastPOSIXct(heating_widemax_TFX$Zeit, required.components = 5L)

#Plot Kessel_Leistung over time
ggplot(data = heating_widemax_TFX, aes(x = Zeit, y = Kessel_Leistung)) +
         geom_line()
```

Plot all.Build over time --> = Temperature??

```{r}
ggplot(data = heating_widemax_TFX, aes(x = Zeit, y = Text.all.Build)) +
  geom_line()
```

Plot Gesamt_Leistung over time

```{r}
heating_widemax_TFX$Gesamt <- heating_widemax_TFX$Kessel_Leistung + heating_widemax_TFX$BHKW_Leistung
heating_widemax_TFX <- subset(heating_widemax_TFX, select = -c(Kessel_Leistung, BHKW_Leistung))

ggplot(data = heating_widemax_TFX, aes(x = Zeit, y = Gesamt)) +
        geom_line()
plot(heating_widemax_TFX$Gesamt)
```

subset only containing occupancy data

```{r}

heating_widemax_TFX_Occ <- heating_widemax_TFX[, grepl("Occ", names(heating_widemax_TFX))]
heating_widemax_TFX_Occ[] <- lapply(heating_widemax_TFX_Occ, as.factor)

#remove "general" rooms since they are assumed to have to influence in change in temp
# -> basis that never changes
# remove columns with nas --> IDEA: can this be done automatically

heating_widemax_TFX_Occ$Occ.Build.all <- NULL
heating_widemax_TFX_Occ$Occ.TGRhoenI.all <- NULL
heating_widemax_TFX_Occ$Occ.TGRhoenII.all <-  NULL
heating_widemax_TFX_Occ$Occ.TGRhoenIII.all <- NULL
heating_widemax_TFX_Occ$Occ.TGVogelsberg.all <- NULL
heating_widemax_TFX_Occ$Occ.Zi18.all <- NULL
heating_widemax_TFX_Occ$Occ.Zi9A.all <- NULL
heating_widemax_TFX_Occ$Occ.TGVogelsberg.all <- NULL

#subtract 1 from each value in df1 since true = 2 and false = 1
heating_widemax_TFX_Occ[] <- lapply(heating_widemax_TFX_Occ, as.integer)
subtract1 <- function(x){
  return(x-1)
}
heating_widemax_TFX_Occ[] <- lapply(heating_widemax_TFX_Occ, subtract1)
heating_widemax_TFX_Occ <- cbind(heating_widemax_TFX_Occ, heating_widemax_TFX$Zeit)
summary(heating_widemax_TFX_Occ)
```

Plot Auslastung over time

```{r}
heating_widemax_TFX_Occ$AuslastungSum <- rowSums(heating_widemax_TFX_Occ[,0:35])
ggplot(data = heating_widemax_TFX_Occ, aes(x = heating_widemax_TFX$Zeit, y = AuslastungSum)) +
  geom_line()
```

Plot Auslastungsquote over time
```{r}
#Quote
heating_widemax_TFX_Occ$Auslastungsquote <- heating_widemax_TFX_Occ$AuslastungSum/35
ggplot(data = heating_widemax_TFX_Occ, aes(x = heating_widemax_TFX$Zeit, y = Auslastungsquote)) +
  geom_line()
```

```{r}
heating_widemax_TFX_Occ$Date <- fastDate(substr(heating_widemax_TFX_Occ$`heating_widemax_TFX$Zeit`, 0, 10))
heating_widemax_TFX_Occ$weekday <- as.factor(weekdays(heating_widemax_TFX_Occ$Date))
heating_widemax_TFX_Occ[heating_widemax_TFX_Occ$weekday == "Samstag" | heating_widemax_TFX_Occ$weekday ==  "Sonntag", "weekend"] <- 1
heating_widemax_TFX_Occ[heating_widemax_TFX_Occ$weekday == "Montag" | heating_widemax_TFX_Occ$weekday ==  "Dienstag" | heating_widemax_TFX_Occ$weekday ==  "Mittwoch" | 
                          heating_widemax_TFX_Occ$weekday ==  "Donnerstag" | heating_widemax_TFX_Occ$weekday ==  "Freitag", "weekend"] <- 0

heating_widemax_TFX_Occ$weekend <- as.integer(heating_widemax_TFX_Occ$weekend)
cor(heating_widemax_TFX_Occ$Auslastungsquote, heating_widemax_TFX_Occ$weekend)
```

BarChart with mean Auslastungsquote per Weekday

```{r}
meanAuslastungsquote <- aggregate(heating_widemax_TFX_Occ$Auslastungsquote, list(heating_widemax_TFX_Occ$weekday), mean)
ggplot(meanAuslastungsquote, aes(Group.1, x)) +
  geom_bar(stat = "identity")
```

Boxplot with mean Auslastungsquote per Weekday

```{r}
ggplot(heating_widemax_TFX_Occ, aes(x = factor(weekday), y = Auslastungsquote)) + 
  geom_boxplot()
```

Add TFX-energy usage data to subset

```{r}

heating_widemax_TFX_Occ <- cbind(heating_widemax_TFX_Occ, heating_widemax_TFX$LeistungGesamt)
colnames(heating_widemax_TFX_Occ)[which(names(heating_widemax_TFX_Occ) == "heating_widemax_TFX$LeistungGesamt")] <- "LeistungGesamt"
colnames(heating_widemax_TFX_Occ)[which(names(heating_widemax_TFX_Occ) == "heating_widemax_TFX$Zeit")] <- "Zeit"

heating_widemax_TFX_Occ$month <- as.factor(month(heating_widemax_TFX_Occ$Zeit))
heating_widemax_TFX_Occ$week <- as.factor(week(heating_widemax_TFX_Occ$Zeit))

ggplot(heating_widemax_TFX_Occ, aes(x = Zeit, y = LeistungGesamt)) +
  geom_line()
```

Plot mean Leistung per week (attention: week 1 is following year)
Remark: 2nd axis for mean Auslastungsquote, AQ is still plotted in 1st axis 
--> *100 and /100 to make impression of fit to 2nd axis

```{r}
heating_widemax_TFX_Occ %>%
  group_by(week) %>%
    summarise(mean_Leistung_week = mean(LeistungGesamt), meanAuslastungWeek = mean(Auslastungsquote)) %>%
      ggplot() + 
        geom_bar(aes(x = week, y = mean_Leistung_week), stat = "identity", fill = "grey") + 
        labs(title = "Mean Leistung and Auslastungsquote per week, 2. HJ 2020, Hotel Kurpark") +
        geom_line(aes(x = week, y = meanAuslastungWeek*100), group = 1, color = "black", size = 1)  +
        scale_y_continuous(name = "Mean Leistung per Week", 
                           sec.axis = sec_axis(~. /100, name = "Mean Auslastungsquote per week"))
```

CHECK!!! mean Auslastungsquote?

```{r}
heating_widemax_TFX_Occ %>%
  filter(month == "11") %>%
    ggplot() + 
    geom_bar(aes(x = Date, y = LeistungGesamt), stat = "identity", fill = "grey") + 
    labs(title = "Sum Leistung and Auslastungsquote, 2. HJ 2020, Hotel Kurpark") +
    geom_line(aes(x = Date, y = Auslastungsquote*6000), group = 1, color = "black", size = 1)  +
    scale_y_continuous(name = "Summe Leistung", 
                       sec.axis = sec_axis(~. /6000, name = "Auslastungsquote"))

```


# 3 - Modelling

BOOTCAMP: MODELLING

## 3.1 - Linear Model

Linear model on November data set

```{r}

wide_nov <- wide_data_Nov2020


```

```{r}

wide_nov <- wide_nov %>%
  mutate_if(is.character, as.factor)

```


```{r}
wide_nov$X.1 <- NULL
wide_nov$HotelID.x <- NULL
wide_nov$Kessel_Leistung <- NULL
wide_nov$BHKW_Leistung <- NULL
```


```{r}
nas <- sapply(wide_nov, function(x) sum(is.na(x)))
wide_nov[nas == 2880] <- NULL
```


```{r}
not_unique <- function(wide_nov) length(unique(wide_nov)) > 1

wide_nov2 <- wide_nov %>% 
  select_if(not_unique)
```

```{r}

wide_nov2$X <- NULL
wide_nov2$Date <- NULL
wide_nov2$Time <- NULL
wide_nov2$X.1 <- NULL

wide_nov2$BHKW_Leistung <- NULL
wide_nov2$Kessel_Leistung <- NULL

```

```{r}
wide_nov2 <- wide_nov2 %>%
  mutate_if(is.character, as.factor)

write.csv(wide_nov2, "C:/Users/chris/Downloads/wide_nov2.csv")
```

```{r}

summary(wide_nov2$Td.Zi21.Bad)

```


```{r}

lm1 <- lm(LeistungGesamt ~ ., data = wide_nov2)
summary(lm1)


```

## 3.2 - Elastic net: not final!
```{r}

# Installing the package
#install.packages("dplyr")

# Loading package
#library(dplyr)

# Installing Packages
#install.packages("dplyr")
#install.packages("glmnet")
#install.packages("ggplot2")
#install.packages("caret")

#library(dplyr)
#library(glmnet)
#library(ggplot2)
#library(caret)

# X and Y datasets
#X <- wide_nov2 %>%
 # select(LeistungGesamt) %>%
 # scale(center = TRUE, scale = FALSE) %>%
 # as.matrix()
#Y <- wide_nov2 %>%
 # select(-LeistungGesamt) %>%
 # as.matrix()

# Model Building : Elastic Net Regression
#control <- trainControl(method = "repeatedcv",
                     #   number = 5,
                     #   repeats = 5,
                     #   search = "random",
                      #  verboseIter = TRUE)

# Training ELastic Net Regression model
#elastic_model <- train(LeistungGesamt ~ .,
                 #      data = cbind(X, Y),
                 #      method = "glmnet",
                 #      preProcess = c("center", "scale"),
                  #     tuneLength = 25,
                 #      trControl = control)

#elastic_model

# Model Prediction
#x_hat_pre <- predict(elastic_model, Y)
#x_hat_pre

# Multiple R-squared
#rsq <- cor(X, x_hat_pre)^2
#rsq

# Plot
#plot(elastic_model, main = "Elastic Net Regression")


```

## 3.3 - Lasso  

True/False -> 0/1
```{r}

cols <- sapply(wide_nov2, is.logical)
wide_nov3 <- wide_nov2
wide_nov3[,cols] <- lapply(wide_nov2[,cols], as.numeric)

```

Data types
```{r}

wide_nov3 <- wide_nov3 %>%
  mutate_if(is.factor, as.numeric)

```

Split into dependent and independent variables (x, y) and run Lasso

```{r}

y <- wide_nov3$LeistungGesamt
x <- wide_nov3 %>%
  select(-LeistungGesamt) %>%
  as.matrix()

library(glmnet)
cv_model <- cv.glmnet(x, y, alpha = 1)
best_lambda <-cv_model$lambda.min
best_lambda

plot(cv_model)

lasso_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(lasso_model)

```

Open point as NEXT STEP: Create train and test set to see model performance

Predicting with lasso an train (!) data

```{r}

lasso_pred <- predict(lasso_model, x)

lasso_result <- as.data.frame(cbind(wide_nov3$LeistungGesamt, lasso_pred))
plot(lasso_result$V1, lasso_result$s0)

```

```{r}

library(Metrics)
rmse(wide_nov3$LeistungGesamt, lasso_pred)

```



Fabians Area


## 3.4 - Regression Trees

Niclas Area


-- Added to functions --
```{r}
#Heating_Data_Nov2020_Num <- Heating_Data_Nov2020 
#Heating_Data_Nov2020_Num $Occ <- as.numeric(Heating_Data_Nov2020_Num $Occ)
#Heating_Data_Nov2020_Num $Win <- as.numeric(Heating_Data_Nov2020_Num $Win)

## 0 is NA 1 is not occupied 2 is occupied
## 0 is NA 1 is no open window detected 2 is open window detected
```


```{r}
# Aggregate the Num Dataset.
#hd_Nov_2020_Agg <- Heating_Data_Nov2020_Num  %>% group_by(Date,Time,Room) %>% summarise(ClIn = median(ClIn, na.rm = TRUE), Occ = sum(Occ, na.rm = TRUE), T = mean(T, na.rm=TRUE), Td = mean(Td, na.rm =TRUE), Text = mean(Text, na.rm =TRUE), Val = mean(Val, na.rm =TRUE), Win = sum(Win, na.rm =TRUE))

# Save as CSV
#getwd()
#write.csv(write.csv(hd_Nov_2020_Agg, "C:/Users/Niclas Bardo Bayer/Desktop/Unsortierte Dateien/BAMP Daten Analyse/BAMP/Heating_Nov_2020_Agg.csv"))
```


```{r}
hd_Nov_2020_Agg$Occ <- as.factor(hd_Nov_2020_Agg$Occ)
summary(hd_Nov_2020_Agg)

```


```{r}
install.packages("esquisse")
library(esquisse)
esquisser(Heating_Nov_2020_Agg)
```

```{r}
Heating_Nov_2020_Agg$Date <- as.Date(Heating_Nov_2020_Agg$Date)
```

```{r}
table(Heating_Nov_2020_Agg$Room, Heating_Nov_2020_Agg$Occ)
```

```{r}
#Data Quality of the Heating Data Set

library(dlookr)
HotelamKurpark_2.HJ2020_heating %>%
  diagnose_web_report(subtitle = "HotelamKurpark_2.HJ2020_heating", output_dir = "./",output_file = "HotelamKurpark_2.HJ2020_heating.html", theme = "blue")
```

```{r}
HotelamKurpark_2_HJ2020_heating_widemax_TFX <- HotelamKurpark_2_HJ2020_heating_widemax_TFX[,-c(1)]
```

```{r}
wide_data_Nov2020 %>% mutate_if(is.character,as.factor)
summary(wide_data_Nov2020)
```



```{r}
wide_data_Nov2020 %>%
  diagnose_web_report(subtitle = "wide_data_Nov2020", output_dir = "./",output_file = "wide_data_Nov2020.html", theme = "blue")



```



Use of simple Regression Tree for Prediction of the Energy Consumption

```{r}
library(rsample)     # data splitting 
library(dplyr)       # data wrangling
library(rpart)       # performing regression trees
library(rpart.plot)  # plotting regression trees
library(ipred)       # bagging
library(caret)       # bagging
#install.packages("tree")
library(tree)
```

```{r}
set.seed(42)
alpha <- 0.8 #Percentage of the training set
inTrain   <- sample(1:nrow(wide_nov2), alpha * nrow(wide_nov2))
train.set <- wide_nov2[inTrain,]
test.set  <- wide_nov2[-inTrain,]
```

```{r}
tree_m1 <- rpart(LeistungGesamt~.,train.set, method = "anova")
rpart.plot(tree_m1)
```


```{r}
## See the accuracy of the model
test_pred_mytree <- predict(tree_m1, test.set)
test_pred_mytree
table(test_pred_mytree)
```

```{r}
## Measure the MSE of the unpruned tree
MSEup = (mean((test_pred_mytree-test.set$LeistungGesamt)^2))
MSEup
## The Mean Squared Error is 626.0145 for this model
## This is a very high error so we need to improve the model. 

## As in this model the window detection seems to have a high influence
## we remove it as it is a binary factor that is based on an algorithm.
```
```{r}
mean(test.set$LeistungGesamt)
```
```{r}
boxplot(test.set$LeistungGesamt)
summary(wide_nov2$LeistungGesamt)
```

To scale the model accross multiple hotels it might make sense to assign the consumption into buckets. 

```{r}
wide_nov2$LeistungsKlasse <- wide_nov2 %>% mutate(new_bin = cut(LeistungGesamt, breaks=c(0, 67, 92, 111)))

```

```{r}
Heating_data_Nov2020_agg_widemax_TFX$GesamtLeistung <-NULL
Heating_data_Nov2020_agg_widemax_TFX$Kessel_Leistung <- NULL
Heating_data_Nov2020_agg_widemax_TFX$BHKW_Leistung <- NULL
Heating_data_Nov2020_agg_widemax_TFX$datetime <- NULL
Heating_data_Nov2020_agg_widemax_TFX$Zeit <- NULL
Heating_data_Nov2020_agg_widemax_TFX$...1 <- NULL
Heating_data_Nov2020_agg_widemax_TFX$Date.y <- NULL
Heating_data_Nov2020_agg_widemax_TFX$Time.y <- NULL
```

```{r}
Heating_data_Nov2020_agg_widemax_TFX_addData$datetime <- NULL
Heating_data_Nov2020_agg_widemax_TFX_addData$Time.y <- NULL
Heating_data_Nov2020_agg_widemax_TFX_addData$Date <- NULL
Heating_data_Nov2020_agg_widemax_TFX_addData$Zeithour <- NULL
Heating_data_Nov2020_agg_widemax_TFX_addData$Zeit <- NULL
Heating_data_Nov2020_agg_widemax_TFX_addData$Kessel_Leistung <- NULL
Heating_data_Nov2020_agg_widemax_TFX_addData$BHKW_Leistung <- NULL
Heating_data_Nov2020_agg_widemax_TFX_addData$date <- NULL
Tree_DS <- Heating_data_Nov2020_agg_widemax_TFX_addData
summary(Tree_DS)
```


```{r}
set.seed(42)
alpha <- 0.8 #Percentage of the training set
inTrain   <- sample(1:nrow(Tree_DS), alpha * nrow(Tree_DS))
train.set <- Tree_DS[inTrain,]
test.set  <- Tree_DS[-inTrain,]
tree_m2 <- rpart(LeistungGesamt~.,train.set, method = "anova")
rpart.plot(tree_m2)
```
```{r}
## See the accuracy of the model
test_pred_mytree <- predict(tree_m2, test.set)
test_pred_mytree
table(test_pred_mytree)

## Measure the MSE of the unpruned tree
RSQE = sqrt(mean((test_pred_mytree-test.set$LeistungGesamt)^2))
RSQE
```




## 3.5 - Random Forest

```{r}
library(randomForest)
library(MASS)
install.packages("MLmetrics")
library(MLmetrics)
library(ipred)
library(tree)
```

```{r}
rmse_reg <- function(model_obj, testing = NULL, target = NULL) {
  #Calculates rmse for a regression decision tree
  #Arguments:
  # testing - test data set
  # target  - target variable (length 1 character vector)
  yhat <- predict(model_obj, newdata = testing)
  actual <- testing[[target]]
  sqrt(mean((yhat-actual)^2))
}

```

```{r}
set.seed(1)
Random_Forest_1 <- randomForest(LeistungGesamt ~ ., data = Tree_DS, mtry = ncol(train.set)-1, importance = TRUE)
rmse_reg(Random_Forest_1, train.set, "medv") # This is a massive improvement over the previous models (classification, prunning, bagging...)

plot(Random_Forest_1,col = "blue", type = "l")
```
```{r}
randomForest::varImpPlot(Random_Forest_1)[,1]
```
```{r}
rmse_reg(Random_Forest_1, test.set, "LeistungGesamt")
```
```{r}
# See if we can plot a part of the Random Forest as a tree. 
install.packages("reprtree")
library(reprtree)
reprtree:::plot.getTree(Random_Forest_1)
```

Add new variables (From here one only tested stuff to see if we could get an index for the occupancy and also added the Consumption Cluster)

```{r}
Heating_data_Nov2020_agg_widemax_TFX$GesamtLeistung <- Heating_data_Nov2020_agg_widemax_TFX$BHKW_Leistung + Heating_data_Nov2020_agg_widemax_TFX$Kessel_Leistung
summary(Heating_data_Nov2020_agg_widemax_TFX$GesamtLeistung)

```
```{r}
Heating_data_Nov2020_agg_widemax_TFX$Consumption_Cluster <- cut(Heating_data_Nov2020_agg_widemax_TFX$GesamtLeistung, 3, labels=c("Low", "Medium", 'High'))
```

```{r}
Heating_data_Nov2020_agg_widemax_TFX %>% select(starts_with("O")) table(Heating_data_Nov2020_agg_widemax_TFX$Consumption_Cluster)
```
```{r}
Occupancy_Matrix <- Heating_data_Nov2020_agg_widemax_TFX %>% select(starts_with("Occ"))
length(Occupancy_Matrix)
```
```{r}
df_dummy <- for i in Occupancy_Matrix {
  if 
}
```

# 4 - Modelling with aggregated data set

1) Data cleansing and reduce number of columns

```{r}
data <- heating_final

data <- subset(data, select = -c(datetime, Date, Kessel_Leistung, BHKW_Leistung, Zeithour, Avg_Temp, date, OccSum, OccRate))
data <- subset(data, select = -c(Zeit))
```


Train test split of "final" data set 
Seed 42

```{r}

set.seed(42)

alpha <- 0.8 #Percentage of the training set
inTrain   <- sample(1:nrow(data), alpha * nrow(data))
train.set <- data[inTrain,]
test.set  <- data[-inTrain,]


```

Kick out date and Holiday (localName) for now, have to be converted to numeric factors!!

```{r}
train.set <- subset(train.set, select = -c(localName, Time.y))


```


Dataformatting

```{r}



```
```{r}

train.set <- train.set %>%
  mutate_if(is.factor, as.numeric)

```



2) Split y and y + run lasso

```{r}

y <- train.set$LeistungGesamt
x <- train.set %>%
  select(-LeistungGesamt) %>%
  as.matrix()

library(glmnet)
cv_model <- cv.glmnet(x, y, alpha = 1)
best_lambda <-cv_model$lambda.min
best_lambda

plot(cv_model)

lasso_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)
coef(lasso_model)


```

--> Occ and Win should be 0 and 1 (and n/a) instead of 1,2,3

Normalizing data!

```{r}
summary(train.set$T.Zi9)

```
```{r}
summary(train.set$Val.Zi9)
```

```{r}
cor(train.set$T.Zi9, train.set$LeistungGesamt)
```

```{r}

df <- Heating_Data_Nov2020_Agg

df$Zeit <- df$Date
df <- df %>% left_join(TFX_all, by = "Zeit")

df$LeistungGesamt <- df$Kessel_Leistung + df$BHKW_Leistung

ggplot(data = train.set, aes(x = Td.Zi9, y = LeistungGesamt)) +
  geom_point()

```

```{r}

```



```{r}


test.set <- test.set  %>%
  mutate_if(is.factor, as.numeric)

test.set  <- subset(test.set , select = -c(localName, Time.y))



y <- test.set $LeistungGesamt
x <- test.set  %>%
  select(-LeistungGesamt) %>%
  as.matrix()



lasso_pred <- predict(lasso_model, x)

lasso_result <- as.data.frame(cbind(test.set$LeistungGesamt, lasso_pred))
plot(lasso_result$V1, lasso_result$s0)


```


```{r}

library(Metrics)
rmse(test.set$LeistungGesamt, lasso_pred)

```



# 5 - End






